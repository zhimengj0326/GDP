{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def generate_data(num):\n",
    "    samples = np.empty(shape=(0, 2))\n",
    "    k = 2\n",
    "    while samples.shape[0]<num:\n",
    "        x_1 = np.random.uniform(0, 1, num)\n",
    "        x_2 = np.random.uniform(0, 1, num)\n",
    "        z = np.array([x_1, x_2]).T\n",
    "        u = np.random.uniform(0, k, num)\n",
    "        index = np.where(u <= x_1 + x_2)[0]\n",
    "        samples = np.append(samples, z[index,:], axis=0)\n",
    "    # samples_num = samples[:num, :]\n",
    "    return samples[:num, 0], samples[:num, 1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_err(xaxis, results, labels, xylabels, title=None, path=None, plottype=None):\n",
    "    with PdfPages(f'{path}/{title.replace(\" \", \"_\")}.pdf') as pdf:\n",
    "        for i, (result, label) in enumerate(zip(results, labels)):\n",
    "            if plottype=='semilogx':\n",
    "                plt.semilogx(xaxis, result, label=label, color=f'C{i}')\n",
    "            elif plottype=='semilogy': \n",
    "                plt.semilogy(xaxis, result, label=label, color=f'C{i}')\n",
    "            elif plottype=='loglog': \n",
    "                plt.loglog(xaxis, result, label=label, color=f'C{i}')\n",
    "            else: \n",
    "                plt.plot(xaxis, result, label=label, color=f'C{i}')\n",
    "        if title:\n",
    "            plt.title(title)\n",
    "        plt.xlabel(xylabels[0])\n",
    "        plt.ylabel(xylabels[1])\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        if path:\n",
    "            pdf.savefig()\n",
    "        plt.show()\n",
    "        # plt.cla()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num = int(1e3)\n",
    "x_train, y_train = generate_data(num)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eg_length = 50\n",
    "np_x = np.linspace(0, 1, eg_length)\n",
    "width = np_x[1] - np_x[0]\n",
    "np_histx = np.concatenate(([np_x[0]-width/2], np_x + width/2), axis=0)\n",
    "cond_mean = (1/2 * np_x + 1/3) / (np_x + 1/2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### ['gau', 'epa', 'uni', 'tri', 'biw', 'triw', 'cos', 'cos2']\n",
    "kernels_regression =  ['gaussian','tricube', 'aitchison_aitken_reg']\n",
    "results_regression = [cond_mean]\n",
    "for kernel in kernels_regression:\n",
    "    kde = KernelReg(endog=y_train, exog=x_train, var_type='c', ckertype=kernel) ## bw='cv_ls', \n",
    "    # estimator = kde.fit(np_x)[1][:,0]\n",
    "    estimator = kde.fit(np_x)[0]\n",
    "    results_regression.append(estimator)\n",
    "\n",
    "labels = ['ground truth', 'gaussian', 'tricube', 'aitchison_aitken']\n",
    "xylabels = ['x', 'regression']\n",
    "title = 'kernel regression'\n",
    "path = 'results/syn'\n",
    "xaxis = np_x\n",
    "plot_err(xaxis, results_regression, labels, xylabels, title, path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bws = np.array([1e-2, 5e-2, 1e-1, 5e-1, 1.0, 2.0]).reshape(-1, 1)\n",
    "bws = np.exp(np.linspace(-5, -0.5, 40)).reshape(-1, 1)\n",
    "results_err = [0] * len(kernels_regression)\n",
    "for i, kernel in enumerate(kernels_regression):\n",
    "    result = []\n",
    "    for bw in bws:\n",
    "        kde = KernelReg(endog=y_train, exog=x_train, var_type='c', bw=bw, ckertype=kernel) ## bw='cv_ls', \n",
    "        # estimator = kde.fit(np_x)[1][:,0]\n",
    "        estimator = kde.fit(np_x)[0]\n",
    "        mse = mean_squared_error(cond_mean, estimator)\n",
    "        result.append(mse)\n",
    "    results_err[i] = result\n",
    "    \n",
    "labels = ['gaussian', 'tricube', 'aitchison_aitken']\n",
    "xylabels = ['bandwidth', 'regression mse']\n",
    "title = 'regression error'\n",
    "path = 'results/syn'\n",
    "xaxis = bws\n",
    "plot_err(xaxis, results_err, labels, xylabels, title, path, plottype='loglog')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure()\n",
    "plt.scatter(x_train, y_train, c='red')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Scatter plot')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# eg_length = 50\n",
    "# np_x = np.linspace(-4, 4, eg_length)\n",
    "length = max(np_x) - min(np_x)\n",
    "pdf_true = np_x + 1/2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bws = [0.1, 0.2, 0.5]\n",
    "kernels_kde = ['gaussian', 'cosine', 'linear', 'exponential']\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "plt.subplot(131)\n",
    "bw = bws[0]\n",
    "plt.hist(x_train, bins=int(np.floor(length/bw)), density=True, histtype='step', color=f'C{0}', label='histgram') # \n",
    "plt.plot(np_x, pdf_true, c=f'C{1}', label='True')\n",
    "for i, kernel in enumerate(kernels_kde):\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bw).fit(x_train[:, np.newaxis])\n",
    "    dens = np.exp(kde.score_samples(np_x[:, np.newaxis]))\n",
    "    plt.plot(np_x, dens, c=f'C{i+2}', label=kernel)\n",
    "plt.title(f'bandwidth={bw}')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('pdf')\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.subplot(132)\n",
    "bw = bws[1]\n",
    "plt.hist(x_train, bins=int(np.floor(length/bw)), density=True, histtype='step', color=f'C{0}', label='histgram') # \n",
    "plt.plot(np_x, pdf_true, c=f'C{1}', label='True')\n",
    "for i, kernel in enumerate(kernels_kde):\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bw).fit(x_train[:, np.newaxis])\n",
    "    dens = np.exp(kde.score_samples(np_x[:, np.newaxis]))\n",
    "    plt.plot(np_x, dens, c=f'C{i+2}', label=kernel)\n",
    "plt.title(f'bandwidth={bw}')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('pdf')\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.subplot(133)\n",
    "bw = bws[2]\n",
    "plt.hist(x_train, bins=int(np.floor(length/bw)), density=True, histtype='step', color=f'C{0}', label='histgram') # \n",
    "plt.plot(np_x, pdf_true, c=f'C{1}', label='True')\n",
    "for i, kernel in enumerate(kernels_kde):\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bw).fit(x_train[:, np.newaxis])\n",
    "    dens = np.exp(kde.score_samples(np_x[:, np.newaxis]))\n",
    "    plt.plot(np_x, dens, c=f'C{i+2}', label=kernel)\n",
    "plt.title(f'bandwidth={bw}')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('pdf')\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def true_DP(np_x):\n",
    "    DP_true = 1/48\n",
    "    return DP_true"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def error_bw_single(bw, num, kernels_kde, kernels_regression):\n",
    "    x_train, y_train = generate_data(num)\n",
    "\n",
    "    eg_length = np.floor(1 / bw).astype(int)\n",
    "    np_x = np.linspace(0, 1, eg_length)\n",
    "    width = np_x[1] - np_x[0]\n",
    "    np_histx = np.concatenate(([np_x[0]-width/2], np_x + width/2), axis=0)\n",
    "\n",
    "    num2 = int(1e4)\n",
    "    np_x2 = np.linspace(1/num2, 1-1/num2, num2)\n",
    "    DP_true = true_DP(np_x2)\n",
    "\n",
    "    ## histogram\n",
    "    (hist_pdf, _, _) = plt.hist(x_train, bins=np_histx, density=True, histtype='step') # \n",
    "    plt.close()\n",
    "    hist_regressions = []\n",
    "    inds = np.digitize(x_train, np_histx)\n",
    "    for index_np in range(len(np_x)):\n",
    "        index = np.where(inds==index_np+1)\n",
    "        if index[0].size:\n",
    "            hist_regression = np.mean(y_train[index])\n",
    "        else:\n",
    "            hist_regression = 0\n",
    "        hist_regressions.append(hist_regression)\n",
    "\n",
    "    results_regression = []\n",
    "    eg_length = int(1e3)\n",
    "    np_x = np.linspace(1/eg_length, 1-1/eg_length, eg_length)\n",
    "    for kernel in kernels_regression:\n",
    "        kde = KernelReg(endog=y_train, exog=x_train, var_type='c', bw=[width], ckertype=kernel) ## bw='cv_ls', \n",
    "        # estimator = kde.fit(np_x)[1][:,0]\n",
    "        estimator = kde.fit(np_x)[0]\n",
    "        results_regression.append(estimator)\n",
    "    dens = []\n",
    "    for i, kernel in enumerate(kernels_kde):\n",
    "        kde = KernelDensity(kernel=kernel, bandwidth=width).fit(x_train[:, np.newaxis])\n",
    "        den = np.exp(kde.score_samples(np_x[:, np.newaxis]))\n",
    "        dens.append(den)\n",
    "    DP_ests = []\n",
    "    ### histgram\n",
    "    DP_est = np.sum(np.abs(hist_regressions - np.mean(y_train)) * hist_pdf)/ np.sum(hist_pdf)\n",
    "    DP_ests.append(DP_est)\n",
    "    for j in range(len(kernels_regression)):\n",
    "        for i in range(len(kernels_kde)):\n",
    "            DP_est = np.sum(np.abs(results_regression[j] - np.mean(y_train)) * dens[i])/ np.sum(dens[i])\n",
    "            DP_ests.append(DP_est)\n",
    "    DP_ests = np.array(DP_ests)\n",
    "    error = np.abs(DP_true - DP_ests)\n",
    "    return error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def error_bw(bw, num, kernels_kde, kernels_regression, times=100):\n",
    "    errors = Parallel(n_jobs=10)(delayed(error_bw_single)(bw, num, kernels_kde, kernels_regression) for i in range(times))\n",
    "    errors = np.array(errors)\n",
    "    return np.mean(errors, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def error_optbw(bws, nums, kernels_kde, kernels_regression, times=100):\n",
    "    errors_opt = np.ones((len(nums), 1+len(kernels_kde)*len(kernels_regression)))\n",
    "    width_opt = np.zeros((len(nums), 1+len(kernels_kde)*len(kernels_regression)))\n",
    "    for i, num in enumerate(nums):\n",
    "        for bw in bws:\n",
    "            errors = Parallel(n_jobs=10)(delayed(error_bw_single)(bw, num, kernels_kde, kernels_regression) for i in range(times))\n",
    "            errors = np.mean(np.array(errors), axis=0)\n",
    "            for j in range(len(errors)):\n",
    "                if errors[j] < errors_opt[i, j]:\n",
    "                    errors_opt[i, j] = errors[j]\n",
    "                    width_opt[i, j] = bw\n",
    "    return errors_opt.T, width_opt.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kernels_regression =  ['tricube', 'aitchison_aitken_reg']\n",
    "kernels_kde = ['linear', 'cosine']\n",
    "num = int(1e3)\n",
    "# bw = 0.1\n",
    "bws = np.exp(np.linspace(-5, -1, 40))\n",
    "# bws = [0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "errors = []\n",
    "for bw in bws:\n",
    "    error = error_bw(bw, num, kernels_kde, kernels_regression)\n",
    "    # error = error_bw_single(bw, num, kernels_kde, kernels_regression)\n",
    "    \n",
    "    errors.append(list(error))\n",
    "# errors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = ['histogram', 'tri-lin', 'tri-cos', 'aa-lin', 'aa-cos']\n",
    "xylabels = ['bandwidth', 'DP_error']\n",
    "title = 'DP_error'\n",
    "# path = 'results/Gaussian'\n",
    "xaxis = bws\n",
    "errors_trans = list(np.array(errors).T)\n",
    "plot_err(xaxis, errors_trans, labels, xylabels, title, path, plottype='loglog')##semilogx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kernels_regression =  ['tricube', 'aitchison_aitken_reg']\n",
    "kernels_kde = ['linear', 'cosine']\n",
    "# bw = 0.1\n",
    "bws = np.exp(np.linspace(-5, -2, 40))\n",
    "nums = np.floor(np.power(10, np.linspace(2, 5, 10))).astype(int) ## num = [10, 50, 100, 500, 1000, 2000, 5000]\n",
    "errors_opt, width_opt = error_optbw(bws, nums, kernels_kde, kernels_regression, times=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = ['histogram', 'tri-lin', 'tri-cos', 'aa-lin', 'aa-cos']\n",
    "xylabels = ['Samples numbers', 'DP_error']\n",
    "title = 'DP_opt_bw'\n",
    "# path = 'results/Gaussian'\n",
    "xaxis = nums\n",
    "plot_err(xaxis, errors_opt, labels, xylabels, title, path, plottype='loglog')##semilogx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = ['histogram', 'tri-lin', 'tri-cos', 'aa-lin', 'aa-cos']\n",
    "xylabels = ['Samples numbers', 'bandwidth']\n",
    "title = 'opt_bw'\n",
    "# path = 'results/Gaussian'\n",
    "xaxis = nums\n",
    "plot_err(xaxis, width_opt, labels, xylabels, title, path, plottype='semilogx')##semilogx"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('FairGNN': conda)"
  },
  "interpreter": {
   "hash": "0d59e7d005459ab828d94ac9f2d56b31a41082ea097fd0fe8ce9027cd475c3ea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}